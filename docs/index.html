<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>CSGNet</title>
    <meta name="generator" content="pandoc">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="author" content="Gopal Sharma">
    <meta name="dcterms.date" content="2018-03-18">
    <meta name="description" content="CSGNet: Neural Shape Parser for Constructive Solid Geometry">
    <meta name="keywords" content="CSGNet, RL, Shape Parsing, Program Induction, Inverse Graphics">
    <link rel="stylesheet" href="stylesheets/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="stylesheets/cayman.css">
    <link rel="stylesheet" href="stylesheets/highlight.css">
    <script src="javascripts/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <link rel="stylesheet" href="stylesheets/your_custom.css">
    <link rel="stylesheet" href="stylesheets/another_stylesheet.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">CSGNet</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/hippogriff/CSGNet" class="btn">View on GitHub</a>
      <a href="https://github.com/hippogriff/CSGNet/archive/master.zip" class="btn">Download .zip</a>
      <a href="https://github.com/hippogriff/CSGNet/archive/master.tar.gz" class="btn">Download .tar.gz</a>
    </section>
    <section class="main-content">
 
<h1 id="csgnet-neural-shape-parser-for-constructive-solid-geometry">CSGNet: Neural Shape Parser for Constructive Solid Geometry</h1>
<p>This repository contains code accompaning the paper: <a href="https://arxiv.org/abs/1712.08290">CSGNet: Neural Shape Parser for Constructive Solid Geometry, CVPR 2018</a>.</p>
<p>Here we only include the code for 2D CSGNet. Code for 3D is available on this <a href="https://github.com/Hippogriff/3DCSGNet">repository</a>.</p>
<p><img src="docs/image.png" /></p>
<h3 id="dependency">Dependency</h3>
<ul>
<li>
Python 3.*
</li>
<li>
<p>Please use conda env using environment.yml file.</p>
<pre class="bash"><code>conda env create -f environment.yml -n CSGNet
source activate CSGNet</code></pre>
</li>
</ul>
<h3 id="data">Data</h3>
<ul>
<li>
<p>Synthetic Dataset:</p>
<p>Download the synthetic <a href="https://www.dropbox.com/s/ud3oe7twjc8l4x3/synthetic.tar.gz?dl=0">dataset</a> and CAD <a href="https://www.dropbox.com/s/d6vm7diqfp65kyi/cad.h5?dl=0">Dataset</a>. Synthetic dataset is provided in the form of program expressions, instead of rendered images. Images for training, validation and testing are rendered on the fly. The dataset is split in different program lengths. <code>bash   tar -zxvf synthetic.tar.gz -C data/</code></p>
</li>
<li>
<p>CAD Dataset</p>
<p>Dataset is provided in H5Py format. <code>bash   mv cad.h5 data/cad/</code></p>
</li>
</ul>
<h3 id="supervised-learning">Supervised Learning</h3>
<ul>
<li>
<p>To train, update <code>config_synthetic.yml</code> with required arguments. Default arguments are already filled. Then run: <code>python   python train_synthetic.py</code></p>
</li>
<li>
<p>To test, update <code>config_synthetic.yml</code> with required arguments. Default arguments are already filled. Then run: <code>python   # For top-1 testing   python test_synthetic.py</code> <code>python   # For beam-search-k testing   python test_synthetic_beamsearch.py</code></p>
</li>
</ul>
<h3 id="rl-fintuning">RL fintuning</h3>
<ul>
<li>
<p>To train a network using RL, fill up configuration in <code>config_cad.yml</code> or keep the default values and then run: <code>python   python train_cad.py</code> Make sure that you have trained a network used Supervised setting first.</p>
</li>
<li>
<p>To test the network trained using RL, fill up configuration in <code>config_cad.yml</code> or keep the default values and then run:</p>
<pre class="python"><code># for top-1 decoding
python test_cad.py</code></pre>
<pre class="python"><code># beam search decoding
python test_cad_beamsearch.py</code></pre>
<p>For post processing optmization of program expressions (visually guided search), set the flag <code>REFINE=True</code> in the script <code>test_cad_beam_search.py</code>, although it is little slow. For saving visualization of beam search use <code>SAVE_VIZ=True</code></p>
</li>
<li>
<p>To optmize some expressions for cad dataset:</p>
<pre><code># To optmize program expressions from top-1 prediction
python refine_cad.py path/to/exp/to/optmize/exp.txt  path/to/directory/to/save/exp/</code></pre>
<p>Note that the expression files here should only have 3k expressions corresponding to the 3k test examples from the CAD dataset.</p>
</li>
<li>
<p>To optmize program expressions from top-1 prediction</p>
<pre><code>python refine_cad_beamsearch.py path/to/exp/to/optmize/exp.txt  path/to/directory/to/save/exp/</code></pre>
<p>Note that the expression files here should only have 3k x beam_width expressions corresponding to the 3k test examples from the CAD dataset.</p>
</li>
</ul>
<h3 id="contact">Contact</h3>
<p>To ask questions, please <a href="mailto:gopalsharma@cs.umass.edu">email</a>.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/jasonlong/cayman-theme">Cayman</a> is maintained by <a href="https://github.com/jasonlong">jasonlong</a>.</span>
        <span class="site-footer-credits">This page was generated with <a href="https://tajmone.github.io/gh-themes-magick/"><strong>gh-themes-magick</strong></a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  </body>
</html>
